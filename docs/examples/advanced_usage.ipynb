{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Usage with TimeCopilot\n",
    "\n",
    "This notebook demonstrates advanced features of TimeCopilot, including:\n",
    "\n",
    "- Working with multiple time series (panel data)\n",
    "- Custom model configurations\n",
    "- Advanced querying and explanations\n",
    "- Ensemble forecasting\n",
    "- Working with different frequencies and seasonal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from timecopilot import TimeCopilot\n",
    "from timecopilot.forecaster import TimeCopilotForecaster\n",
    "from timecopilot.models.benchmarks import (\n",
    "    AutoETS, AutoARIMA, SeasonalNaive, \n",
    "    HistoricAverage, Theta, DynamicOptimizedTheta\n",
    ")\n",
    "from timecopilot.models.foundational.timesfm import TimesFM\n",
    "from timecopilot.models.benchmarks.prophet import Prophet\n",
    "\n",
    "# Set styling\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Multiple Time Series\n",
    "\n",
    "TimeCopilot excels at handling panel data with multiple time series. Let's create a synthetic dataset with multiple series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic multi-series data\n",
    "def create_synthetic_panel_data(n_series=5, n_periods=100, freq='D'):\n",
    "    \"\"\"Create synthetic panel data with different patterns\"\"\"\n",
    "    \n",
    "    # Create date range\n",
    "    dates = pd.date_range(start='2020-01-01', periods=n_periods, freq=freq)\n",
    "    \n",
    "    series_data = []\n",
    "    \n",
    "    for i in range(n_series):\n",
    "        # Create different patterns for each series\n",
    "        if i == 0:  # Trend + seasonality\n",
    "            trend = np.linspace(100, 200, n_periods)\n",
    "            seasonal = 20 * np.sin(2 * np.pi * np.arange(n_periods) / 7)  # Weekly seasonality\n",
    "            noise = np.random.normal(0, 5, n_periods)\n",
    "            y = trend + seasonal + noise\n",
    "            series_id = \"retail_sales\"\n",
    "            \n",
    "        elif i == 1:  # Strong seasonality\n",
    "            base = 50\n",
    "            seasonal = 30 * np.sin(2 * np.pi * np.arange(n_periods) / 365.25)  # Annual seasonality\n",
    "            weekly = 10 * np.sin(2 * np.pi * np.arange(n_periods) / 7)  # Weekly seasonality\n",
    "            noise = np.random.normal(0, 3, n_periods)\n",
    "            y = base + seasonal + weekly + noise\n",
    "            series_id = \"website_traffic\"\n",
    "            \n",
    "        elif i == 2:  # Exponential growth\n",
    "            growth_rate = 0.001\n",
    "            y = 10 * np.exp(growth_rate * np.arange(n_periods)) + np.random.normal(0, 2, n_periods)\n",
    "            series_id = \"user_signups\"\n",
    "            \n",
    "        elif i == 3:  # Random walk\n",
    "            y = np.cumsum(np.random.normal(0, 1, n_periods)) + 100\n",
    "            series_id = \"stock_price\"\n",
    "            \n",
    "        else:  # Cyclical pattern\n",
    "            cycle = 25 * np.sin(2 * np.pi * np.arange(n_periods) / 30)  # Monthly cycle\n",
    "            trend = 0.1 * np.arange(n_periods)\n",
    "            noise = np.random.normal(0, 4, n_periods)\n",
    "            y = 80 + cycle + trend + noise\n",
    "            series_id = \"inventory_levels\"\n",
    "        \n",
    "        # Create DataFrame for this series\n",
    "        series_df = pd.DataFrame({\n",
    "            'unique_id': series_id,\n",
    "            'ds': dates,\n",
    "            'y': y\n",
    "        })\n",
    "        \n",
    "        series_data.append(series_df)\n",
    "    \n",
    "    return pd.concat(series_data, ignore_index=True)\n",
    "\n",
    "# Generate panel data\n",
    "panel_df = create_synthetic_panel_data(n_series=3, n_periods=150, freq='D')\n",
    "\n",
    "print(f\"Panel data shape: {panel_df.shape}\")\n",
    "print(f\"Unique series: {panel_df['unique_id'].unique()}\")\n",
    "print(f\"Date range: {panel_df['ds'].min()} to {panel_df['ds'].max()}\")\n",
    "panel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the panel data\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "for i, series_id in enumerate(panel_df['unique_id'].unique()):\n",
    "    series_data = panel_df[panel_df['unique_id'] == series_id]\n",
    "    axes[i].plot(series_data['ds'], series_data['y'], linewidth=2, label=series_id)\n",
    "    axes[i].set_title(f'Time Series: {series_id}')\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel('Value')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Agent Usage\n",
    "\n",
    "Let's use the TimeCopilot agent with more sophisticated queries and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent with more sophisticated configuration\n",
    "agent = TimeCopilot(\n",
    "    model=\"openai:gpt-4o-mini\",  # Use more capable model for complex analysis\n",
    "    # Add any additional configuration here\n",
    ")\n",
    "\n",
    "# Generate forecast with detailed analysis\n",
    "complex_query = \"\"\"\n",
    "Analyze these three time series and provide insights on:\n",
    "1. The dominant patterns in each series (trend, seasonality, cyclical)\n",
    "2. Which series are most predictable and why\n",
    "3. Any relationships or correlations between the series\n",
    "4. Recommendations for forecasting each series\n",
    "5. Potential risks or uncertainties in the forecasts\n",
    "\"\"\"\n",
    "\n",
    "result = agent.forecast(\n",
    "    df=panel_df,\n",
    "    h=30,  # Forecast 30 days ahead\n",
    "    freq=\"D\",  # Daily frequency\n",
    "    level=[80, 95],  # Prediction intervals\n",
    "    query=complex_query\n",
    ")\n",
    "\n",
    "print(\"Advanced forecast completed!\")\n",
    "print(f\"Forecast shape: {result.forecast.shape}\")\n",
    "print(f\"Series forecasted: {result.forecast['unique_id'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the detailed analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"DETAILED ANALYSIS FROM TIMECOPILOT AGENT\")\n",
    "print(\"=\" * 60)\n",
    "print(result.explanation)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Ensemble\n",
    "\n",
    "Create a custom ensemble of models for more robust forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive ensemble of models\n",
    "ensemble_models = [\n",
    "    # Statistical models\n",
    "    AutoETS(),\n",
    "    AutoARIMA(),\n",
    "    SeasonalNaive(),\n",
    "    Theta(),\n",
    "    DynamicOptimizedTheta(),\n",
    "    \n",
    "    # Machine learning models\n",
    "    Prophet(),\n",
    "    \n",
    "    # Foundation models\n",
    "    TimesFM(),\n",
    "    \n",
    "    # Simple baselines\n",
    "    HistoricAverage(),\n",
    "]\n",
    "\n",
    "# Create ensemble forecaster\n",
    "ensemble_forecaster = TimeCopilotForecaster(models=ensemble_models)\n",
    "\n",
    "# Generate ensemble forecasts\n",
    "ensemble_forecasts = ensemble_forecaster.forecast(\n",
    "    df=panel_df,\n",
    "    h=21,  # 3 weeks\n",
    "    freq=\"D\",\n",
    "    level=[80, 95]\n",
    ")\n",
    "\n",
    "print(f\"Ensemble forecasts shape: {ensemble_forecasts.shape}\")\n",
    "print(f\"Models in ensemble: {len(ensemble_forecasts['model'].unique())}\")\n",
    "print(f\"Models: {ensemble_forecasts['model'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Analysis\n",
    "\n",
    "Evaluate the performance of different models using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation with the ensemble\n",
    "cv_results = ensemble_forecaster.cross_validation(\n",
    "    df=panel_df,\n",
    "    h=7,  # Forecast 1 week ahead\n",
    "    freq=\"D\",\n",
    "    n_windows=5,  # 5 cross-validation windows\n",
    "    step_size=7   # Weekly steps\n",
    ")\n",
    "\n",
    "print(f\"Cross-validation results shape: {cv_results.shape}\")\n",
    "print(f\"CV windows: {cv_results['cutoff'].nunique()}\")\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive performance metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate various performance metrics\"\"\"\n",
    "    return {\n",
    "        'mae': mean_absolute_error(y_true, y_pred),\n",
    "        'mse': mean_squared_error(y_true, y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'mape': mean_absolute_percentage_error(y_true, y_pred) * 100,\n",
    "    }\n",
    "\n",
    "# Calculate metrics by model and series\n",
    "performance_results = []\n",
    "\n",
    "for series_id in cv_results['unique_id'].unique():\n",
    "    series_data = cv_results[cv_results['unique_id'] == series_id]\n",
    "    \n",
    "    for model in series_data['model'].unique():\n",
    "        model_data = series_data[series_data['model'] == model]\n",
    "        \n",
    "        if len(model_data) > 0:\n",
    "            metrics = calculate_metrics(model_data['y'], model_data['y_pred'])\n",
    "            metrics.update({\n",
    "                'series_id': series_id,\n",
    "                'model': model,\n",
    "                'n_predictions': len(model_data)\n",
    "            })\n",
    "            performance_results.append(metrics)\n",
    "\n",
    "performance_df = pd.DataFrame(performance_results)\n",
    "print(\"Model Performance by Series:\")\n",
    "performance_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Visualization\n",
    "\n",
    "Create comprehensive visualizations to understand model performance and forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance heatmap\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Heatmap of MAPE by model and series\n",
    "mape_pivot = performance_df.pivot(index='model', columns='series_id', values='mape')\n",
    "sns.heatmap(mape_pivot, annot=True, fmt='.1f', cmap='YlOrRd', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('MAPE by Model and Series (%)')\n",
    "\n",
    "# Heatmap of RMSE by model and series\n",
    "rmse_pivot = performance_df.pivot(index='model', columns='series_id', values='rmse')\n",
    "sns.heatmap(rmse_pivot, annot=True, fmt='.1f', cmap='YlOrRd', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('RMSE by Model and Series')\n",
    "\n",
    "# Box plot of MAPE by model\n",
    "performance_df.boxplot(column='mape', by='model', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('MAPE Distribution by Model')\n",
    "axes[1, 0].set_xlabel('Model')\n",
    "axes[1, 0].set_ylabel('MAPE (%)')\n",
    "\n",
    "# Box plot of RMSE by series\n",
    "performance_df.boxplot(column='rmse', by='series_id', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('RMSE Distribution by Series')\n",
    "axes[1, 1].set_xlabel('Series')\n",
    "axes[1, 1].set_ylabel('RMSE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecasts for each series\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "for i, series_id in enumerate(panel_df['unique_id'].unique()):\n",
    "    # Historical data\n",
    "    historical = panel_df[panel_df['unique_id'] == series_id]\n",
    "    axes[i].plot(historical['ds'], historical['y'], 'b-', linewidth=2, label='Historical')\n",
    "    \n",
    "    # Agent forecast\n",
    "    agent_forecast = result.forecast[result.forecast['unique_id'] == series_id]\n",
    "    agent_forecast['ds'] = pd.to_datetime(agent_forecast['ds'])\n",
    "    axes[i].plot(agent_forecast['ds'], agent_forecast['y'], 'r--', linewidth=2, label='Agent Forecast')\n",
    "    \n",
    "    # Add prediction intervals\n",
    "    if 'lo-80' in agent_forecast.columns:\n",
    "        axes[i].fill_between(agent_forecast['ds'], agent_forecast['lo-80'], agent_forecast['hi-80'], \n",
    "                           alpha=0.3, color='red', label='80% PI')\n",
    "    \n",
    "    # Add top 3 ensemble models\n",
    "    series_performance = performance_df[performance_df['series_id'] == series_id].sort_values('mape')\n",
    "    top_models = series_performance.head(3)['model'].tolist()\n",
    "    \n",
    "    colors = ['green', 'orange', 'purple']\n",
    "    for j, model in enumerate(top_models):\n",
    "        model_forecast = ensemble_forecasts[\n",
    "            (ensemble_forecasts['unique_id'] == series_id) & \n",
    "            (ensemble_forecasts['model'] == model)\n",
    "        ]\n",
    "        if len(model_forecast) > 0:\n",
    "            model_forecast['ds'] = pd.to_datetime(model_forecast['ds'])\n",
    "            axes[i].plot(model_forecast['ds'], model_forecast['y'], \n",
    "                        color=colors[j], linestyle=':', linewidth=2, label=f'{model} (Top {j+1})')\n",
    "    \n",
    "    axes[i].set_title(f'Forecasts for {series_id}')\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel('Value')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Use Cases\n",
    "\n",
    "Let's demonstrate some specific advanced use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case 1: Forecast with different horizons for different series\n",
    "custom_forecasts = {}\n",
    "\n",
    "for series_id in panel_df['unique_id'].unique():\n",
    "    series_data = panel_df[panel_df['unique_id'] == series_id]\n",
    "    \n",
    "    # Different horizons based on series characteristics\n",
    "    if 'retail' in series_id:\n",
    "        h = 14  # 2 weeks for retail\n",
    "    elif 'traffic' in series_id:\n",
    "        h = 7   # 1 week for web traffic\n",
    "    else:\n",
    "        h = 30  # 1 month for others\n",
    "    \n",
    "    # Get best model for this series\n",
    "    best_model_name = performance_df[performance_df['series_id'] == series_id].sort_values('mape').iloc[0]['model']\n",
    "    \n",
    "    # Find the best model object\n",
    "    best_model = None\n",
    "    for model in ensemble_models:\n",
    "        if model.__class__.__name__ == best_model_name:\n",
    "            best_model = model\n",
    "            break\n",
    "    \n",
    "    if best_model:\n",
    "        custom_forecaster = TimeCopilotForecaster(models=[best_model])\n",
    "        forecast = custom_forecaster.forecast(df=series_data, h=h, freq=\"D\")\n",
    "        custom_forecasts[series_id] = {\n",
    "            'forecast': forecast,\n",
    "            'horizon': h,\n",
    "            'model': best_model_name\n",
    "        }\n",
    "\n",
    "print(\"Custom forecasts generated:\")\n",
    "for series_id, info in custom_forecasts.items():\n",
    "    print(f\"{series_id}: {info['horizon']} days with {info['model']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case 2: Query-driven analysis\n",
    "business_queries = [\n",
    "    \"Which series shows the most growth potential?\",\n",
    "    \"What are the key risk factors for each forecast?\",\n",
    "    \"How do seasonal patterns differ between series?\",\n",
    "    \"What external factors might influence these forecasts?\"\n",
    "]\n",
    "\n",
    "for query in business_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Use agent to answer specific question\n",
    "    query_result = agent.forecast(\n",
    "        df=panel_df,\n",
    "        h=7,  # Short horizon for quick analysis\n",
    "        freq=\"D\",\n",
    "        query=query\n",
    "    )\n",
    "    \n",
    "    print(query_result.explanation[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### Key Advanced Features:\n",
    "\n",
    "1. **Multi-Series Forecasting**: TimeCopilot handles panel data seamlessly\n",
    "2. **Model Ensembles**: Combine multiple models for robust forecasting\n",
    "3. **Custom Configurations**: Tailor forecasts to specific business needs\n",
    "4. **Performance Evaluation**: Use cross-validation for model selection\n",
    "5. **Intelligent Querying**: Get specific insights through natural language\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Data Quality**: Ensure clean, consistent time series data\n",
    "2. **Model Selection**: Use cross-validation to choose the best model for each series\n",
    "3. **Ensemble Approach**: Combine multiple models for better robustness\n",
    "4. **Business Context**: Include domain knowledge in queries\n",
    "5. **Validation**: Always validate forecasts against business logic\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Experiment with different model combinations\n",
    "- Integrate with your specific business data\n",
    "- Set up automated forecasting pipelines\n",
    "- Monitor forecast accuracy over time\n",
    "- Use insights to drive business decisions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}